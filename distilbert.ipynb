{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac4c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DISTILBERT.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1zgdmSQx89GWepVH-kRgK_4a8mtTPqNJ-\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4636f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b195416",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a93744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a920be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U transformers datasets\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec67007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all file names and labels\n",
    "files = {\n",
    "    \"twitter_parsed_dataset.csv\": \"twitter\",\n",
    "    \"twitter_racism_parsed_dataset.csv\": \"racism\",\n",
    "    \"twitter_sexism_parsed_dataset.csv\": \"sexism\",\n",
    "    \"youtube_parsed_dataset.csv\": \"youtube\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ae22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, label in files.items():\n",
    "    df = pd.read_csv(file)\n",
    "    text_col = None\n",
    "    for col in df.columns:\n",
    "        if 'text' in col.lower():\n",
    "            text_col = col\n",
    "            break\n",
    "    if not text_col:\n",
    "        raise ValueError(f\"Couldn't find a text column in {file}\")\n",
    "    df = df[[text_col]].dropna().copy()\n",
    "    df.columns = ['text']\n",
    "    df['label'] = label\n",
    "    all_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(all_dfs).reset_index(drop=True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee43d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 2000 entries per label to balance the dataset\n",
    "sample_df = final_df.groupby('label').apply(lambda x: x.sample(n=2000, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb49508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels into integers\n",
    "le = LabelEncoder()\n",
    "sample_df['label_encoded'] = le.fit_transform(sample_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "sample_df[['label', 'label_encoded']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b2455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets (90/10 split)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91520f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    sample_df['text'].tolist(),\n",
    "    sample_df['label_encoded'].tolist(),\n",
    "    test_size=0.1,\n",
    "    stratify=sample_df['label_encoded'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize train and validation sets\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f27bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild train and validation into HF-compatible Dataset format\n",
    "train_dict = {\n",
    "    'text': train_texts,\n",
    "    'label': train_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a709fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = {\n",
    "    'text': val_texts,\n",
    "    'label': val_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639dc27b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(train_dict)\n",
    "val_dataset = Dataset.from_dict(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344f5ac",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(example):\n",
    "    return tokenizer(example['text'], truncation=True, padding='max_length', max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813750fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename label column for Trainer compatibility\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "val_dataset = val_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set format to PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51763ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique labels (classes)\n",
    "num_labels = len(set(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdae15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained DistilBERT model with classification head\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daced503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d1d233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48556527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "num_labels = len(set(train_labels))  # or len(set(sample_df['label_encoded']))\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353ae50",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, EvalPrediction\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, preds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8063564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d83e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on validation set\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3abc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e5587",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(final_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b97db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74016118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b8d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c4076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U transformers datasets\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a22db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all file names and labels\n",
    "files = {\n",
    "    \"toxicity_parsed_dataset.csv\": \"toxicity\",\n",
    "    \"twitter_racism_parsed_dataset.csv\": \"racism\",\n",
    "    \"twitter_sexism_parsed_dataset.csv\": \"sexism\",\n",
    "    \"youtube_parsed_dataset.csv\": \"youtube\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7284c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79684dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, label in files.items():\n",
    "    df = pd.read_csv(file)\n",
    "    text_col = None\n",
    "    for col in df.columns:\n",
    "        if 'text' in col.lower():\n",
    "            text_col = col\n",
    "            break\n",
    "    if not text_col:\n",
    "        raise ValueError(f\"Couldn't find a text column in {file}\")\n",
    "    df = df[[text_col]].dropna().copy()\n",
    "    df.columns = ['text']\n",
    "    df['label'] = label\n",
    "    all_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2929a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(all_dfs).reset_index(drop=True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add76b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ce9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the smallest class count\n",
    "min_count = 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe652b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced list\n",
    "balanced = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe610b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each label and resample\n",
    "for label in final_df[\"label\"].unique():\n",
    "    label_df = final_df[final_df[\"label\"] == label]\n",
    "    if len(label_df) > min_count:\n",
    "        resampled = resample(label_df, replace=False, n_samples=min_count, random_state=42)\n",
    "    else:\n",
    "        resampled = resample(label_df, replace=True, n_samples=min_count, random_state=42)\n",
    "    balanced.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a367ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all balanced samples\n",
    "balanced_df = pd.concat(balanced).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079267ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new distribution\n",
    "print(\"New Label Distribution:\")\n",
    "print(balanced_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New label encoding\n",
    "label_map = {'toxicity': 0, 'racism': 1, 'youtube': 2, 'sexism': 3}\n",
    "balanced_df['label_encoded'] = balanced_df['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d23f185",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf8c7d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"clean_text\"] = balanced_df[\"text\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets (90/10 split)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a690dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    balanced_df['text'].tolist(),\n",
    "    balanced_df['label_encoded'].tolist(),\n",
    "    test_size=0.1,\n",
    "    stratify=balanced_df['label_encoded'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf247ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d18407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize train and validation sets\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01370857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94faab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild train and validation into HF-compatible Dataset format\n",
    "train_dict = {\n",
    "    'text': train_texts,\n",
    "    'label': train_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6b5f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = {\n",
    "    'text': val_texts,\n",
    "    'label': val_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46264f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(train_dict)\n",
    "val_dataset = Dataset.from_dict(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea08c6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(example):\n",
    "    return tokenizer(example['text'], truncation=True, padding='max_length', max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1427f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81caab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename label column for Trainer compatibility\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "val_dataset = val_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b832d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set format to PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05124a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification# Number of unique labels (classes)num_labels = len(set(train_labels))# Load pretrained DistilBERT model with classification headmodel = DistilBertForSequenceClassification.from_pretrained(    'distilbert-base-uncased',    num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e6ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6b116",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc9d3b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(axis=1)\n",
    "    labels = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"macro_f1\": f1_score(labels, preds, average='macro')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcff04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e545b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on validation set\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68081f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a7e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_encodings = tokenizer(\n",
    "    val_texts,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c16ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels_tensor = torch.tensor(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6bf7d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d867f305",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class ValDataset(Dataset):\n",
    "    def _init_(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'label': self.labels[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ca122",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c301796",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ccf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "\n",
    "        label_key = 'label' if 'label' in batch else 'labels'\n",
    "        labels = batch[label_key].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4613dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f69b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names (edit if needed)\n",
    "label_names = ['toxicity', 'racism', 'youtube', 'sexism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd259c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be102f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"distilbert_model/\")\n",
    "tokenizer.save_pretrained(\"distilbert_model/\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
